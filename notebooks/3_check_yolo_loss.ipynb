{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from tfyolo3 import YoloV3, losses\n",
    "from tfyolo3.dataloaders import YoloDatasetSingleFile\n",
    "from tfyolo3.dataloaders import common\n",
    "from tfyolo3.helpers import draw\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to understand how the yolo loss works\n",
    "\n",
    "The first create some random anchors and use the default masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 14.],\n",
       "       [10., 15.],\n",
       "       [15., 16.],\n",
       "       [20., 28.],\n",
       "       [25., 32.],\n",
       "       [30., 36.],\n",
       "       [35., 36.],\n",
       "       [40., 47.],\n",
       "       [45., 48.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(5, 46, 5)\n",
    "anchors = np.array(list(zip(x,x)), dtype=np.float32)\n",
    "anchors[:,1] += np.random.randint(0, 10, 9)\n",
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 8],\n",
       "       [3, 4, 5],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = YoloV3.default_masks\n",
    "masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a toy dataset\n",
    "\n",
    "make the following cell executable to download the toy dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%capture\n",
    "\n",
    "!wget https://www.dropbox.com/s/drjtl8hjy42lq42/toy_dataset.tar.gz\n",
    "!tar -xf toy_dataset.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load the dataset using the SequenceDataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('./toy_dataset/data_annotations_train.txt')\n",
    "target_shape = (256, 256, 3)\n",
    "batch_size = 2\n",
    "gridlen = 8\n",
    "is_training = True\n",
    "max_objects = 10\n",
    "\n",
    "\n",
    "train_seq = YoloDatasetSingleFile(filepath,\n",
    "                                  target_shape,\n",
    "                                  max_objects,\n",
    "                                  batch_size, \n",
    "                                  anchors,\n",
    "                                  masks,\n",
    "                                  is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a batch from the dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true, y_true_grids = train_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch contains:\n",
    "- 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_true_grids)): \n",
    "    print(i, '-->', y_true_grids[i].shape, target_shape[0] / y_true_grids[i].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third value plotted represents the size in number of pixel of grid cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the dataset transformed is correct\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_idx in range(len(x_true)):\n",
    "    print('Show annotations for image', img_idx)\n",
    "    img = x_true[img_idx]\n",
    "\n",
    "    for i in range(len(y_true_grids)):\n",
    "        y_data_grid_img = y_true_grids[i][img_idx]\n",
    "        \n",
    "        ax = draw.show_img(img)\n",
    "        grid_len = y_data_grid_img.shape[1]\n",
    "        draw.grid(ax, img.shape[:2], grid_len)\n",
    "\n",
    "        grid_cell_size = target_shape[1] / grid_len\n",
    "        \n",
    "        for grid_y, grid_x, box in np.argwhere(np.sum(y_data_grid_img[..., :4], axis=-1) > 0):\n",
    "            box_xyxy = (y_data_grid_img[grid_y,grid_x,box, :4] * target_shape[0]).astype(int)\n",
    "            class_id = np.argwhere(y_data_grid_img[grid_y,grid_x,box, 5:])[0][0]\n",
    "            draw.rect(ax, box_xyxy, 'white', 1)\n",
    "\n",
    "            rect_resp = np.array([grid_x, grid_y]) * grid_cell_size\n",
    "            rect_resp = np.concatenate([rect_resp, rect_resp + grid_cell_size])\n",
    "            draw.rect(ax, rect_resp, 'blue', 2)\n",
    "\n",
    "            draw.point(ax, common.to_center_width_height(box_xyxy)[:2])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YoloV3(target_shape, max_objects, anchors=anchors, num_classes=train_seq.num_classes, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model.model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate how the loss works\n",
    "\n",
    "We consider two cases:\n",
    "\n",
    "1. when we got an initialized network the predictions should be around 0.5 (max entropy)\n",
    "1. when we give as prediction the right labels the loss should be close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grids = model(x_true)\n",
    "for y_pred in y_pred_grids:\n",
    "    print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take i=0 since all the images are in the first grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "y_true = y_true_grids[i]\n",
    "y_pred = y_pred_grids[i]\n",
    "anchors_masks = anchors[masks[i]]\n",
    "img_size = target_shape[0]\n",
    "loss_fn = losses.make_loss(train_seq.num_classes, anchors, masks, img_size)\n",
    "ignore_threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfyolo3.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. transform all pred outputs\n",
    "# y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "anchors_masks_scaled = anchors_masks / img_size\n",
    "pred_xyxy, pred_obj, pred_class, pred_xywh = losses.process_predictions(\n",
    "            tf.cast(y_pred, tf.float32), train_seq.num_classes, anchors_masks_scaled\n",
    ")\n",
    "pred_xy = pred_xywh[..., 0:2]\n",
    "pred_wh = pred_xywh[..., 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that considering the variable `pred_xywh` the predictions should be:\n",
    "- for xy in in average 0.5\n",
    "- for wh close to 0\n",
    "- for xy1, xy2 close to 0.5\n",
    "\n",
    "While considering `pred_xyxy` it should be around 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('average xy', tf.reduce_mean(pred_xy))\n",
    "print('average hw', tf.reduce_mean(pred_wh))\n",
    "print('average xyxy', tf.reduce_mean(pred_xyxy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is valid for all the objecteness and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('average pred_obj', tf.reduce_mean(pred_obj))\n",
    "print('average pred_class', tf.reduce_mean(pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. transform all true outputs\n",
    "# y_true: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "true_box_xyxy, true_obj, true_class = tf.split(\n",
    "    y_true, (4, 1, train_seq.num_classes), axis=-1)\n",
    "true_xy = (true_box_xyxy[..., 0:2] + true_box_xyxy[..., 2:4]) / 2\n",
    "true_wh = true_box_xyxy[..., 2:4] - true_box_xyxy[..., 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. inverting the pred box equations, to make it comparable with the transformations done for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = tf.shape(y_true)[1]\n",
    "grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "    tf.cast(grid, tf.float32)\n",
    "\n",
    "true_wh = tf.math.log(true_wh / anchors_masks_scaled)\n",
    "true_wh = tf.where(tf.math.is_inf(true_wh),\n",
    "                   tf.zeros_like(true_wh), true_wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line 8 contains the opposite transformation made for the predictions\n",
    "\n",
    "```\n",
    "box_wh = tf.exp(box_wh) * anchors_masks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks are used to:\n",
    "1. separate the boxes that contain objects and should be considered in the objects loss\n",
    "2. from the boxes that not contain objects and should be considered in the **no object loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. calculate all masks\n",
    "obj_mask = tf.squeeze(true_obj, -1)\n",
    "# ignore false positive when iou is over threshold\n",
    "true_box_mask = tf.boolean_mask(\n",
    "    true_box_xyxy, tf.cast(obj_mask, tf.bool))\n",
    "best_iou = tf.reduce_max(Loss.broadcast_iou(\n",
    "    pred_xyxy, true_box_mask), axis=-1)\n",
    "ignore_mask = tf.cast(best_iou < ignore_threshold, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute all the losses\n",
    "\n",
    "- xy, wh only with respect the objects that contains elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_loss = obj_mask * box_loss_scale * \\\n",
    "    tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "wh_loss = obj_mask * box_loss_scale * \\\n",
    "    tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the object and no object loss\n",
    "\n",
    "You can check the whenever the loss is different to zero in the `obj_loss` is zero in the `no_obj_loss` and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cross_entropy = tf.keras.metrics.binary_crossentropy(\n",
    "    true_obj, pred_obj, from_logits=False)\n",
    "obj_loss = obj_mask * obj_cross_entropy\n",
    "no_obj_loss = (1 - obj_mask) * ignore_mask * obj_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The class loss is computed only for the cells the contains objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_loss = obj_mask * tf.keras.metrics.binary_crossentropy(\n",
    "            true_class, pred_class, from_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- everything is reduced to one value per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "no_obj_loss = tf.reduce_sum(no_obj_loss, axis=(1, 2, 3))\n",
    "class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "loss = xy_loss + wh_loss + obj_loss + no_obj_loss + class_loss\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Case\n",
    "\n",
    "- y_true == y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "y_true = y_true_grids[i]\n",
    "y_pred = y_true_grids[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember that y_pred is in format xy_min xy_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xyxy, pred_obj, pred_class = tf.split(\n",
    "        y_pred, (4, 1, train_seq.num_classes), axis=-1)\n",
    "\n",
    "pred_xy = (pred_xyxy[..., 0:2] + pred_xyxy[..., 2:4]) / 2\n",
    "pred_wh = pred_xyxy[..., 2:4] - pred_xyxy[..., 0:2]\n",
    "\n",
    "pred_xywh = tf.concat((pred_xy, pred_wh), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_box_xyxy, true_obj, true_class = tf.split(\n",
    "            y_true, (4, 1, train_seq.num_classes), axis=-1)\n",
    "true_xy = (true_box_xyxy[..., 0:2] + true_box_xyxy[..., 2:4]) / 2\n",
    "true_wh = true_box_xyxy[..., 2:4] - true_box_xyxy[..., 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "# 4. calculate all masks\n",
    "obj_mask = tf.squeeze(true_obj, -1)\n",
    "# ignore false positive when iou is over threshold\n",
    "true_box_mask = tf.boolean_mask(\n",
    "    true_box_xyxy, tf.cast(obj_mask, tf.bool))\n",
    "best_iou = tf.reduce_max(Loss.broadcast_iou(\n",
    "    pred_xyxy, true_box_mask), axis=-1)\n",
    "ignore_mask = tf.cast(best_iou < ignore_threshold, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. compute all the losses\n",
    "xy_loss = obj_mask * box_loss_scale * \\\n",
    "    tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "wh_loss = obj_mask * box_loss_scale * \\\n",
    "    tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cross_entropy = tf.keras.metrics.binary_crossentropy(\n",
    "    true_obj, pred_obj, from_logits=False)\n",
    "obj_loss = obj_mask * obj_cross_entropy\n",
    "no_obj_loss = (1 - obj_mask) * ignore_mask * obj_cross_entropy\n",
    "\n",
    "class_loss = obj_mask * tf.keras.metrics.binary_crossentropy(\n",
    "    true_class, pred_class, from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "no_obj_loss = tf.reduce_sum(no_obj_loss, axis=(1, 2, 3))\n",
    "class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "loss = xy_loss + wh_loss + obj_loss + no_obj_loss + class_loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is 0 when the prediction is equal to the true values\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "we have verified that the loss:\n",
    "- return max entropy value when the network is initialized, and\n",
    "- return 0 when the y_pred is equal to y_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
